{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf6a3e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c43f8d",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ed577b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_preprocessed = pd.read_parquet('../../Absenteeism_preprocessed.parquet.gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dec348e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reason_1</th>\n",
       "      <th>Reason_2</th>\n",
       "      <th>Reason_3</th>\n",
       "      <th>Reason_4</th>\n",
       "      <th>Month Value</th>\n",
       "      <th>Day of the Week</th>\n",
       "      <th>Transportation Expense</th>\n",
       "      <th>Distance to Work</th>\n",
       "      <th>Age</th>\n",
       "      <th>Daily Work Load Average</th>\n",
       "      <th>Body Mass Index</th>\n",
       "      <th>Education</th>\n",
       "      <th>Children</th>\n",
       "      <th>Pets</th>\n",
       "      <th>Absenteeism Time in Hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>289</td>\n",
       "      <td>36</td>\n",
       "      <td>33</td>\n",
       "      <td>239.554</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>118</td>\n",
       "      <td>13</td>\n",
       "      <td>50</td>\n",
       "      <td>239.554</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>179</td>\n",
       "      <td>51</td>\n",
       "      <td>38</td>\n",
       "      <td>239.554</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>279</td>\n",
       "      <td>5</td>\n",
       "      <td>39</td>\n",
       "      <td>239.554</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>289</td>\n",
       "      <td>36</td>\n",
       "      <td>33</td>\n",
       "      <td>239.554</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Reason_1  Reason_2  Reason_3  Reason_4  Month Value  Day of the Week  \\\n",
       "0         0         0         0         1            7                1   \n",
       "1         0         0         0         0            7                1   \n",
       "2         0         0         0         1            7                2   \n",
       "3         1         0         0         0            7                3   \n",
       "4         0         0         0         1            7                3   \n",
       "\n",
       "   Transportation Expense  Distance to Work  Age  Daily Work Load Average  \\\n",
       "0                     289                36   33                  239.554   \n",
       "1                     118                13   50                  239.554   \n",
       "2                     179                51   38                  239.554   \n",
       "3                     279                 5   39                  239.554   \n",
       "4                     289                36   33                  239.554   \n",
       "\n",
       "   Body Mass Index  Education  Children  Pets  Absenteeism Time in Hours  \n",
       "0               30          0         2     1                          4  \n",
       "1               31          0         1     0                          0  \n",
       "2               31          0         0     0                          2  \n",
       "3               24          0         2     0                          4  \n",
       "4               30          0         2     1                          2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_preprocessed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c57f12b",
   "metadata": {},
   "source": [
    "## Create the targets & inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3901feb3",
   "metadata": {},
   "source": [
    "We use `median` to create goals, because about 50 percent of the sample (or population) is less than that, and the other 50 percent of the sample (or population) is more than that. So it's a good option to classify raw data in a balanced way. The initial classification we apply points to two classes: The **moderately absenteeism** and **excessively absenteeism**. Since we have two classes, we can use **logistic regression**. A 60-40 split will usually work equally well for a logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f7940b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = np.where(data_preprocessed['Absenteeism Time in Hours'] > \n",
    "                   data_preprocessed['Absenteeism Time in Hours'].median(), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c36a33cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_preprocessed['Excessive Absenteeism'] = targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17beca8",
   "metadata": {},
   "source": [
    "After we made the targets, we don't need to `Absenteeism Time in Hours` column, so we remove it from the data. We also remove `Daily Work Load Average`, `Day of the Week` and `Distance to Work` columns beacuse of the reasone we'll see later. The reason is they have little effects(coefficients) on our prediction. You can try and continue the process with presence of the mentioned features and see the effect values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84196b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_targets = data_preprocessed.drop(['Absenteeism Time in Hours', 'Daily Work Load Average',\n",
    "                                           'Day of the Week', 'Distance to Work'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72561af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "unscaled_inputs = data_with_targets.iloc[:, :-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb712fb7",
   "metadata": {},
   "source": [
    "## Standardize the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc7fa4e",
   "metadata": {},
   "source": [
    "Scaling data in preprocess phase is an important step. So we use a custom scaler(for scalability of possible upcomming changes) to standardize only numerical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d7ded6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "class CustomScaler(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, columns, copy=True, with_mean=True, with_std=True):\n",
    "        self.copy = copy\n",
    "        self.with_mean = with_mean\n",
    "        self.with_std = with_std\n",
    "        self.scaler = StandardScaler(copy=copy, with_mean=with_mean, with_std=with_std)\n",
    "        self.columns = columns\n",
    "        self.mean_ = None\n",
    "        self.var_ = None\n",
    "        \n",
    "    def fit(self, X, y = None):\n",
    "        self.scaler.fit(X[self.columns], y)\n",
    "        self.mean_ = np.mean(X[self.columns])\n",
    "        self.var_ = np.var(X[self.columns])\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None, copy=None):\n",
    "        init_col_order = X.columns\n",
    "        X_scaled = pd.DataFrame(self.scaler.transform(X[self.columns]), columns=self.columns)\n",
    "        X_not_scaled = X.loc[:, ~X.columns.isin(self.columns)]\n",
    "        return pd.concat([X_not_scaled, X_scaled], axis = 1)[init_col_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13d2cb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_scale = ['Month Value', 'Transportation Expense', 'Age', 'Body Mass Index', 'Children', 'Pets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84ea08d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "absenteeism_scaler = CustomScaler(columns_to_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a70836c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomScaler(columns=['Month Value', 'Transportation Expense', 'Age',\n",
       "                      'Body Mass Index', 'Children', 'Pets'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "absenteeism_scaler.fit(unscaled_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "784522bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_inputs = absenteeism_scaler.transform(unscaled_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae7191e",
   "metadata": {},
   "source": [
    "## Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ef78c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c56350",
   "metadata": {},
   "source": [
    "Since we're shuffling the data every time we run the cell below, we get a different permutation of the data. We may be lucky and get high accuracies or may be unlucky and receive poor ones. So we need a pseudo-random mechanism to shuffle our data. The parameter `random_state` is the solution. If we use it, then the method will always **shuffle the observations in the same 'random' way**.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1528ac4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(scaled_inputs, targets, test_size = 0.2, random_state = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f021e76e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(560, 11) (560,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68e9a2e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(140, 11) (140,)\n"
     ]
    }
   ],
   "source": [
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338b0e57",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4f9a54",
   "metadata": {},
   "source": [
    "### Mathematical background\n",
    "An explanation of logistic regression can begin with an explanation of the standard logistic function. The logistic function is a sigmoid function, which takes any real input $t$, and outputs a value between zero and one. \n",
    "\n",
    "The standard logistic function $\\sigma : \\mathbb{R} \\rightarrow (0, 1)$ is defined as follows:\n",
    "\n",
    "$$\\sigma (t) = \\frac {e^t}{1 + e^t} = \\frac {1}{1 + e^{-t}}$$\n",
    "\n",
    "Let us assume that $t$ is a linear function of a single explanatory variable $x$. We can then express $t$ as follows:\n",
    "\n",
    "$$t = \\beta_0 + \\beta_1x$$\n",
    "\n",
    "And the general logistic function $p: \\mathbb{R} \\rightarrow (0, 1)$ can now be written as:\n",
    "\n",
    "$$p(x) = \\sigma (t) = \\frac {1}{1 + e^{-(\\beta_0 + \\beta_1x)}}$$\n",
    "\n",
    "In the logistic model, $p(x)$ is interpreted as the probability of the dependent variable $Y$ equaling a success/case rather than a failure/non-case.\n",
    "\n",
    "We can now define the logit (log odds) function as the inverse $g = \\sigma ^ {-1}$ of the standard logistic function. It is easy to see that it satisfies:\n",
    "\n",
    "$$g(p(x)) = \\sigma ^ {-1}(p(x)) = logit p(x) = ln(\\frac {p(x)}{1 - p(x)}) = \\beta_0 + \\beta_1x$$\n",
    "\n",
    "and equivalently, after exponentiating both sides we have the odds:\n",
    "\n",
    "$$\\frac{p(x)}{1 - p(x)} = e^{\\beta_0 + \\beta_1x}$$\n",
    "\n",
    "In our problem, $p(x)$ is the probabilty of excessive absenteeism whereas $1-p(x)$ is the probability of moderate absenteeism. we can estimate the ration(which called `odds`) with an exponetial calcualtion of linear combination of coefficients($\\beta_i$).\n",
    "\n",
    "The `predictors`($\\beta_i$ for $i > 0$) determine the effect of their corresponding feature in final decision making. \n",
    "\n",
    "When the predictors are equal to zero or the probabilities of classes are equal(0.5 in our case), $\\beta_0$ is the value of criterion and it's called `intercept` or `bias`. In other words, bias calibrates the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b488c888",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d4dca82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "86e0cb5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1a68f632",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7732142857142857"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91aaf3f3",
   "metadata": {},
   "source": [
    "## Manually check the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3dcd2907",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_outputs = reg.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8981bb6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7732142857142857"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum((model_outputs == y_train)) / model_outputs.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0072b469",
   "metadata": {},
   "source": [
    "## Interpret coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "204b4185",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_name = unscaled_inputs.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ef1c5dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_table = pd.DataFrame(columns = ['Feature name'], data = feature_name)\n",
    "summary_table['Coefficient'] = np.transpose(reg.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "13013b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_table.index = summary_table.index + 1\n",
    "summary_table.loc[0] = ['Intercept', reg.intercept_[0]]\n",
    "summary_table = summary_table.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6cbb0786",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_table['Odds'] = np.exp(summary_table.Coefficient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "35d04262",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature name</th>\n",
       "      <th>Coefficient</th>\n",
       "      <th>Odds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Reason_3</td>\n",
       "      <td>3.115553</td>\n",
       "      <td>22.545903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Reason_1</td>\n",
       "      <td>2.800197</td>\n",
       "      <td>16.447892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Reason_2</td>\n",
       "      <td>0.951884</td>\n",
       "      <td>2.590585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Reason_4</td>\n",
       "      <td>0.839001</td>\n",
       "      <td>2.314054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Transportation Expense</td>\n",
       "      <td>0.605284</td>\n",
       "      <td>1.831773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Children</td>\n",
       "      <td>0.348262</td>\n",
       "      <td>1.416604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Body Mass Index</td>\n",
       "      <td>0.279811</td>\n",
       "      <td>1.322880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Month Value</td>\n",
       "      <td>0.158930</td>\n",
       "      <td>1.172256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Age</td>\n",
       "      <td>-0.169891</td>\n",
       "      <td>0.843757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Education</td>\n",
       "      <td>-0.210533</td>\n",
       "      <td>0.810152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Pets</td>\n",
       "      <td>-0.277396</td>\n",
       "      <td>0.757754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Intercept</td>\n",
       "      <td>-1.647455</td>\n",
       "      <td>0.192539</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Feature name  Coefficient       Odds\n",
       "3                 Reason_3     3.115553  22.545903\n",
       "1                 Reason_1     2.800197  16.447892\n",
       "2                 Reason_2     0.951884   2.590585\n",
       "4                 Reason_4     0.839001   2.314054\n",
       "6   Transportation Expense     0.605284   1.831773\n",
       "10                Children     0.348262   1.416604\n",
       "8          Body Mass Index     0.279811   1.322880\n",
       "5              Month Value     0.158930   1.172256\n",
       "7                      Age    -0.169891   0.843757\n",
       "9                Education    -0.210533   0.810152\n",
       "11                    Pets    -0.277396   0.757754\n",
       "0                Intercept    -1.647455   0.192539"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_table.sort_values('Odds', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102469f9",
   "metadata": {},
   "source": [
    "As we see, Reason_3(poisoning), Reason_1(various diseases), Reason_2(pregnancy and giving birth), and Reason_4(light diseases) are the most important factors in our model to predict as an excessively absenteesim or a moderately one.\n",
    "\n",
    "**A weight(coefficient) of 0 implies that no matter the feature value, we will multiply it by 0(in the model). And for a unit change in the standardized feature, the odds increase by a multiple equal to the odds ratio(1 = no change).**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1e54f2",
   "metadata": {},
   "source": [
    "## Test the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "46ac3068",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8d487f5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.71340413, 0.28659587],\n",
       "       [0.58724228, 0.41275772],\n",
       "       [0.44020821, 0.55979179],\n",
       "       [0.78159464, 0.21840536],\n",
       "       [0.08410854, 0.91589146],\n",
       "       [0.33487603, 0.66512397],\n",
       "       [0.29984576, 0.70015424],\n",
       "       [0.13103971, 0.86896029],\n",
       "       [0.78625404, 0.21374596],\n",
       "       [0.74903632, 0.25096368],\n",
       "       [0.49397598, 0.50602402],\n",
       "       [0.22484913, 0.77515087],\n",
       "       [0.07129151, 0.92870849],\n",
       "       [0.73178133, 0.26821867],\n",
       "       [0.30934135, 0.69065865],\n",
       "       [0.5471671 , 0.4528329 ],\n",
       "       [0.55052275, 0.44947725],\n",
       "       [0.5392707 , 0.4607293 ],\n",
       "       [0.40201117, 0.59798883],\n",
       "       [0.05361575, 0.94638425],\n",
       "       [0.7003009 , 0.2996991 ],\n",
       "       [0.78159464, 0.21840536],\n",
       "       [0.42037128, 0.57962872],\n",
       "       [0.42037128, 0.57962872],\n",
       "       [0.24783565, 0.75216435],\n",
       "       [0.74566259, 0.25433741],\n",
       "       [0.51017274, 0.48982726],\n",
       "       [0.85690195, 0.14309805],\n",
       "       [0.20349733, 0.79650267],\n",
       "       [0.78159464, 0.21840536],\n",
       "       [0.63043442, 0.36956558],\n",
       "       [0.32093965, 0.67906035],\n",
       "       [0.31497433, 0.68502567],\n",
       "       [0.47131917, 0.52868083],\n",
       "       [0.78159464, 0.21840536],\n",
       "       [0.46493449, 0.53506551],\n",
       "       [0.77852919, 0.22147081],\n",
       "       [0.26307895, 0.73692105],\n",
       "       [0.59501956, 0.40498044],\n",
       "       [0.39494012, 0.60505988],\n",
       "       [0.78924152, 0.21075848],\n",
       "       [0.54775534, 0.45224466],\n",
       "       [0.76248708, 0.23751292],\n",
       "       [0.60166502, 0.39833498],\n",
       "       [0.17244553, 0.82755447],\n",
       "       [0.43202425, 0.56797575],\n",
       "       [0.30886675, 0.69113325],\n",
       "       [0.71340413, 0.28659587],\n",
       "       [0.78064733, 0.21935267],\n",
       "       [0.7966903 , 0.2033097 ],\n",
       "       [0.42371744, 0.57628256],\n",
       "       [0.6705336 , 0.3294664 ],\n",
       "       [0.33487603, 0.66512397],\n",
       "       [0.73050501, 0.26949499],\n",
       "       [0.16678032, 0.83321968],\n",
       "       [0.56508475, 0.43491525],\n",
       "       [0.11625388, 0.88374612],\n",
       "       [0.76872928, 0.23127072],\n",
       "       [0.66584142, 0.33415858],\n",
       "       [0.65567061, 0.34432939],\n",
       "       [0.30090655, 0.69909345],\n",
       "       [0.34505737, 0.65494263],\n",
       "       [0.70755059, 0.29244941],\n",
       "       [0.20799242, 0.79200758],\n",
       "       [0.79249724, 0.20750276],\n",
       "       [0.73159442, 0.26840558],\n",
       "       [0.91291434, 0.08708566],\n",
       "       [0.77852919, 0.22147081],\n",
       "       [0.26754583, 0.73245417],\n",
       "       [0.69469781, 0.30530219],\n",
       "       [0.77852919, 0.22147081],\n",
       "       [0.70985592, 0.29014408],\n",
       "       [0.09561809, 0.90438191],\n",
       "       [0.53938703, 0.46061297],\n",
       "       [0.39825313, 0.60174687],\n",
       "       [0.78159464, 0.21840536],\n",
       "       [0.22645293, 0.77354707],\n",
       "       [0.26837292, 0.73162708],\n",
       "       [0.25831165, 0.74168835],\n",
       "       [0.32855571, 0.67144429],\n",
       "       [0.75417184, 0.24582816],\n",
       "       [0.92387058, 0.07612942],\n",
       "       [0.76872928, 0.23127072],\n",
       "       [0.24741155, 0.75258845],\n",
       "       [0.56558369, 0.43441631],\n",
       "       [0.87775043, 0.12224957],\n",
       "       [0.29572951, 0.70427049],\n",
       "       [0.42037128, 0.57962872],\n",
       "       [0.75881641, 0.24118359],\n",
       "       [0.32093965, 0.67906035],\n",
       "       [0.82488593, 0.17511407],\n",
       "       [0.84950183, 0.15049817],\n",
       "       [0.77374985, 0.22625015],\n",
       "       [0.73159442, 0.26840558],\n",
       "       [0.74903632, 0.25096368],\n",
       "       [0.14944055, 0.85055945],\n",
       "       [0.70403751, 0.29596249],\n",
       "       [0.23713867, 0.76286133],\n",
       "       [0.75645005, 0.24354995],\n",
       "       [0.78203264, 0.21796736],\n",
       "       [0.37671823, 0.62328177],\n",
       "       [0.32093965, 0.67906035],\n",
       "       [0.30409309, 0.69590691],\n",
       "       [0.25542876, 0.74457124],\n",
       "       [0.55063861, 0.44936139],\n",
       "       [0.51677447, 0.48322553],\n",
       "       [0.72259112, 0.27740888],\n",
       "       [0.14944055, 0.85055945],\n",
       "       [0.2220274 , 0.7779726 ],\n",
       "       [0.85521156, 0.14478844],\n",
       "       [0.93001302, 0.06998698],\n",
       "       [0.09640551, 0.90359449],\n",
       "       [0.33736668, 0.66263332],\n",
       "       [0.66154998, 0.33845002],\n",
       "       [0.47623876, 0.52376124],\n",
       "       [0.43903262, 0.56096738],\n",
       "       [0.21378105, 0.78621895],\n",
       "       [0.17783793, 0.82216207],\n",
       "       [0.45811539, 0.54188461],\n",
       "       [0.6906917 , 0.3093083 ],\n",
       "       [0.74041049, 0.25958951],\n",
       "       [0.8393858 , 0.1606142 ],\n",
       "       [0.18777875, 0.81222125],\n",
       "       [0.54775534, 0.45224466],\n",
       "       [0.78159464, 0.21840536],\n",
       "       [0.64457904, 0.35542096],\n",
       "       [0.78924152, 0.21075848],\n",
       "       [0.89029009, 0.10970991],\n",
       "       [0.25937462, 0.74062538],\n",
       "       [0.7003009 , 0.2996991 ],\n",
       "       [0.38415023, 0.61584977],\n",
       "       [0.78924152, 0.21075848],\n",
       "       [0.70403751, 0.29596249],\n",
       "       [0.64457904, 0.35542096],\n",
       "       [0.73490357, 0.26509643],\n",
       "       [0.47623876, 0.52376124],\n",
       "       [0.5392707 , 0.4607293 ],\n",
       "       [0.68498978, 0.31501022],\n",
       "       [0.75645005, 0.24354995],\n",
       "       [0.53938703, 0.46061297]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_proba = reg.predict_proba(x_test)\n",
    "predicted_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d85caf7",
   "metadata": {},
   "source": [
    "## Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "af615b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ca4ddc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model', 'wb') as file:\n",
    "    pickle.dump(reg, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1b10310f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('scaler', 'wb') as file:\n",
    "    pickle.dump(absenteeism_scaler, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ir_env",
   "language": "python",
   "name": "ir_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
